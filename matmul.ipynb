{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "def matmul_python(C, A, B):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] = A[m, k] * B[k, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from importlib.util import find_spec\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "fix = \"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "fix following the steps here:\n",
    "    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def install_if_missing(name: str):\n",
    "    if find_spec(name):\n",
    "        return\n",
    "\n",
    "    print(f\"{name} not found, installing\")\n",
    "    try:\n",
    "        if shutil.which('python3'): python = \"python3\"\n",
    "        elif shutil.which('python'): python =\"python\"\n",
    "        else: raise (\"python not on path\" + fix)\n",
    "    except:\n",
    "        raise ImportError(f\"{name} not found\" + fix)\n",
    "\n",
    "install_if_missing(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from timeit import timeit\n",
    "import numpy as np \n",
    "\n",
    "class Matrix:\n",
    "    def __init__(self, value, rows, cols):\n",
    "        self.value = value\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        return self.value[idxs[0]][idxs[1]]\n",
    "\n",
    "    def __setitem__(self, idxs, value):\n",
    "        self.value[idxs[0]][idxs[1]] = value\n",
    "\n",
    "def benchmark_matmul_python(M, N, K):\n",
    "    A = Matrix(list(np.random.rand(M,K)), M, K)\n",
    "    B = Matrix(list(np.random.rand(K,N)), K, N)\n",
    "    C = Matrix(list(np.zeros((M,N))), M, N)\n",
    "    secs = timeit(lambda: matmul_python(C, A, B), number=2)/2\n",
    "    gflops = ((2*M*N*K)/secs) / 1e9\n",
    "    print(gflops, \"GFLOP/s\")\n",
    "    return gflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002362634740148928 GFLOP/s\n",
      "0.002362634740148928 GFLOP/s\n"
     ]
    }
   ],
   "source": [
    "p_gflops  = benchmark_matmul_python(128, 128, 128).to_float64()\n",
    "print(p_gflops, \"GFLOP/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark import Unit\n",
    "from sys.intrinsics import strided_load\n",
    "from math import div_ceil, min\n",
    "from memory import memset_zero\n",
    "from memory.unsafe import DTypePointer\n",
    "from random import rand, random_float64\n",
    "from sys.info import simdwidthof\n",
    "from runtime.llcl import Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This exactly the same Python implementation,\n",
    "# but is infact Mojo code!\n",
    "def matmul_untyped(C, A, B):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] += A[m, k] * B[k, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn matrix_getitem(self: object, i: object) raises -> object:\n",
    "    return self.value[i]\n",
    "\n",
    "\n",
    "fn matrix_setitem(self: object, i: object, value: object) raises -> object:\n",
    "    self.value[i] = value\n",
    "    return None\n",
    "\n",
    "\n",
    "fn matrix_append(self: object, value: object) raises -> object:\n",
    "    self.value.append(value)\n",
    "    return None\n",
    "\n",
    "\n",
    "fn matrix_init(rows: Int, cols: Int) raises -> object:\n",
    "    let value = object([])\n",
    "    return object(\n",
    "        Attr(\"value\", value), Attr(\"__getitem__\", matrix_getitem), Attr(\"__setitem__\", matrix_setitem),\n",
    "        Attr(\"rows\", rows), Attr(\"cols\", cols), Attr(\"append\", matrix_append),\n",
    "    )\n",
    "\n",
    "def benchmark_matmul_untyped(M: Int, N: Int, K: Int, python_gflops: Float64):\n",
    "    C = matrix_init(M, N)\n",
    "    A = matrix_init(M, K)\n",
    "    B = matrix_init(K, N)\n",
    "    for i in range(M):\n",
    "        c_row = object([])\n",
    "        b_row = object([])\n",
    "        a_row = object([])\n",
    "        for j in range(N):\n",
    "            c_row.append(0.0)\n",
    "            b_row.append(random_float64(-5, 5))\n",
    "            a_row.append(random_float64(-5, 5))\n",
    "        C.append(c_row)\n",
    "        B.append(b_row)\n",
    "        A.append(a_row)\n",
    "\n",
    "    @parameter\n",
    "    fn test_fn():\n",
    "        try:\n",
    "            _ = matmul_untyped(C, A, B)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    let secs = benchmark.run[test_fn](max_runtime_secs=0.5).mean()\n",
    "    _ = (A, B, C)\n",
    "    let gflops = ((2*M*N*K)/secs) / 1e9\n",
    "    let speedup : Float64 = gflops / python_gflops\n",
    "    print(gflops, \"GFLOP/s, a\", speedup, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006482297836650287 GFLOP/s, a 2.743673292572375 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "benchmark_matmul_untyped(128, 128, 128, p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias type = DType.float32\n",
    "\n",
    "struct Matrix:\n",
    "    var data: DTypePointer[type]\n",
    "    var rows: Int\n",
    "    var cols: Int\n",
    "\n",
    "    # Initialize zeroeing all values\n",
    "    fn __init__(inout self, rows: Int, cols: Int):\n",
    "        self.data = DTypePointer[type].alloc(rows * cols)\n",
    "        memset_zero(self.data, rows * cols)\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    # Initialize taking a pointer, don't set any elements\n",
    "    fn __init__(inout self, rows: Int, cols: Int, data: DTypePointer[type]):\n",
    "        self.data = data\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    ## Initialize with random values\n",
    "    @staticmethod\n",
    "    fn rand(rows: Int, cols: Int) -> Self:\n",
    "        let data = DTypePointer[type].alloc(rows * cols)\n",
    "        rand(data, rows * cols)\n",
    "        return Self(rows, cols, data)\n",
    "\n",
    "    fn __getitem__(self, y: Int, x: Int) -> Float32:\n",
    "        return self.load[1](y, x)\n",
    "\n",
    "    fn __setitem__(self, y: Int, x: Int, val: Float32):\n",
    "        return self.store[1](y, x, val)\n",
    "\n",
    "    fn load[nelts: Int](self, y: Int, x: Int) -> SIMD[type, nelts]:\n",
    "        return self.data.simd_load[nelts](y * self.cols + x)\n",
    "\n",
    "    fn store[nelts: Int](self, y: Int, x: Int, val: SIMD[type, nelts]):\n",
    "        return self.data.simd_store[nelts](y * self.cols + x, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that C, A, B have types\n",
    "fn matmul_naive(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] += A[m, k] * B[k, n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias M = 1024\n",
    "alias N = 1024\n",
    "alias K = 1024\n",
    "\n",
    "@always_inline\n",
    "fn bench[\n",
    "    func: fn (Matrix, Matrix, Matrix) -> None](base_gflops: Float64):\n",
    "    var C = Matrix(M, N)\n",
    "    var A = Matrix.rand(M, K)\n",
    "    var B = Matrix.rand(K, N)\n",
    "\n",
    "    @always_inline\n",
    "    @parameter\n",
    "    fn test_fn():\n",
    "        _ = func(C, B, A)\n",
    "\n",
    "    let secs = benchmark.run[test_fn](max_runtime_secs=1).mean()\n",
    "    # Prevent the matrices from being freed before the benchmark run\n",
    "    A.data.free()\n",
    "    B.data.free()\n",
    "    C.data.free()\n",
    "    let gflops = ((2 * M * N * K) / secs) / 1e9\n",
    "    let speedup: Float64 = gflops / base_gflops\n",
    "    print (gflops, \"GFLOP/s, a\", speedup, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5850156665592949 GFLOP/s, a 670.86784073080378 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_naive](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mojo has SIMD vector types, we can vectorize the Matul code as follows.\n",
    "# nelts = number of float32 element that can fit in SIMD register \n",
    "alias nelts = simdwidthof[DType.float32]()\n",
    "fn matmul_vectorized_0(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for nv in range(0, C.cols, nelts):\n",
    "                C.store[nelts](m, nv, C.load[nelts](m,nv) + A[m,k] * B.load[nelts](k,nv))\n",
    "            \n",
    "            # Handle remaining elements with scalars.\n",
    "            for n in range(nelts*(C.cols//nelts), C.cols):\n",
    "                C[m, n] += A[m,k] * B[k,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.439196059027644 GFLOP/s, a 1878.9176268303836 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_vectorized_0](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the code by using the builtin vectorize function\n",
    "from algorithm import vectorize\n",
    "fn matmul_vectorized_1(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows): \n",
    "        for k in range(A.cols):\n",
    "            @parameter\n",
    "            fn dot[nelts: Int](n: Int):\n",
    "                C.store[nelts](m,n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n",
    "            vectorize[nelts, dot](C.cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5999317631493035 GFLOP/s, a 2370.2063073855898 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_vectorized_1](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import parallelize\n",
    "fn matmul_parallized(C: Matrix, A: Matrix, B: Matrix):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        for k in range(A.cols):\n",
    "            @parameter\n",
    "            fn dot[nelts: Int](n: Int):\n",
    "                C.store[nelts](m,n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n",
    "            vectorize[nelts, dot](C.cols)\n",
    "\n",
    "    parallelize[calc_row](C.rows, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5304601304425853 GFLOP/s, a 2340.8020022993373 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_parallized](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import Static2DTileUnitFunc as Tile2DFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 2D tiling on the iteration space defined by end_x and end_y\n",
    "fn tile[tiled_fn: Tile2DFunc, tile_x: Int, tile_y: Int](end_x: Int, end_y: Int):\n",
    "    # Note: this assumes that ends are multiples of the tiles.\n",
    "    for y in range(0, end_y, tile_y):\n",
    "        for x in range(0, end_x, tile_x):\n",
    "            tiled_fn[tile_x, tile_y](x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above tile function to perform tiled matmul.\n",
    "fn matmul_tiled_parallelized(C: Matrix, A: Matrix, B: Matrix):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        @parameter\n",
    "        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y:Int):\n",
    "            for k in range(y, y + tile_y):\n",
    "                @parameter\n",
    "                fn dot[nelts: Int,](n: Int):\n",
    "                    C.store[nelts](m,n + x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n",
    "                vectorize[nelts, dot](tile_x)\n",
    "\n",
    "        # We hardcode the tile factor to be 4\n",
    "        alias tile_size = 4\n",
    "        tile[calc_tile, nelts * tile_size, tile_size](A.cols, C.cols)\n",
    "\n",
    "    parallelize[calc_row](C.rows, C.rows) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.666874273685028 GFLOP/s, a 4514.8215644254196 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_tiled_parallelized](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unroll the vectorized loop by a constant factor.\n",
    "from algorithm import vectorize_unroll\n",
    "fn matmul_tiled_unroll_parallelized(C: Matrix, A: Matrix, B: Matrix):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        @parameter\n",
    "        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n",
    "            for k in range(y, y+ tile_y):\n",
    "                @parameter\n",
    "                fn dot[nelts: Int](n: Int):\n",
    "                    C.store[nelts](m,n+x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n",
    "\n",
    "                # Vectorize by nelts and unroll by tile_x/nelts\n",
    "                # Here unroll factor is 4\n",
    "                vectorize_unroll[nelts, tile_x//nelts, dot](tile_x)\n",
    "\n",
    "        alias tile_size = 4\n",
    "        tile[calc_tile, nelts*tile_size, tile_size](A.cols, C.cols)\n",
    "\n",
    "    parallelize[calc_row](C.rows, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6280941880565916 GFLOP/s, a 1958.8699469325761 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_tiled_unroll_parallelized](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotune import autotune, search\n",
    "from time import now\n",
    "from memory.unsafe import Pointer\n",
    "\n",
    "alias matmul_fn_sig_type = fn(C: Matrix, A: Matrix, B: Matrix, /) -> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autotune the tile size used in the matmul.\n",
    "@adaptive\n",
    "fn matmul_autotune_impl(C: Matrix, A: Matrix, B: Matrix, /):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        @parameter\n",
    "        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n",
    "            for k in range(y, y + tile_y):\n",
    "                @parameter\n",
    "                fn dot[nelts: Int](n: Int):\n",
    "                    C.store[nelts](m,n+x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n",
    "                vectorize_unroll[nelts, tile_x // nelts, dot](tile_x)\n",
    "\n",
    "        # Instead of hardcoding to tile_size = 4, search for the fastest\n",
    "        # tile size by evaluating this function as tile size varies\n",
    "        alias tile_size = autotune(1, 2, 4, 8, 16, 32)\n",
    "        tile[calc_tile, nelts * tile_size, tile_size](A.cols, C.cols)\n",
    "\n",
    "    parallelize[calc_row](C.rows, C.rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn matmul_evaluator(funcs: Pointer[matmul_fn_sig_type], size: Int) -> Int:\n",
    "    print(\"matmul_evaluator, number of candidates: \", size)\n",
    "\n",
    "    let eval_begin: Int = now()\n",
    "\n",
    "    # This size is picked at random, in real code we could use a real size \n",
    "    # distribution here.\n",
    "    let M = 512\n",
    "    let N = 512\n",
    "    let K = 512\n",
    "    print(\"Optimizing for size:\", M, \"x\", N, \"x\", K)\n",
    "\n",
    "    var best_idx: Int = 1\n",
    "    var best_time: Int = -1\n",
    "\n",
    "    alias eval_iteration = 10\n",
    "    alias eval_samples = 10\n",
    "\n",
    "    var C = Matrix(M, N)\n",
    "    var A = Matrix(M, K)\n",
    "    var B = Matrix(K, N)\n",
    "    let Cptr = Pointer[Matrix].address_of(C).address\n",
    "    let Aptr = Pointer[Matrix].address_of(A).address\n",
    "    let Bptr = Pointer[Matrix].address_of(B).address\n",
    "\n",
    "    # Find the function that's the fastest on the size we're optimizing for \n",
    "    for f_idx in range(size):\n",
    "        let func = funcs.load(f_idx)\n",
    "\n",
    "        @always_inline\n",
    "        @parameter\n",
    "        fn wrapper():\n",
    "            func(A, B, C)\n",
    "        let cur_time = benchmark.run[wrapper](max_runtime_secs=0.5).mean(Unit.ns).to_int()\n",
    "\n",
    "        if best_idx < 0:\n",
    "            best_idx = f_idx\n",
    "            best_time = cur_time\n",
    "        if best_time > cur_time:\n",
    "            best_idx = f_idx\n",
    "            best_time = cur_time\n",
    "\n",
    "    let eval_end: Int = now()\n",
    "    # Prevent matrices from being destroyed before we finished bechmarking them.\n",
    "    A.data.free()\n",
    "    B.data.free()\n",
    "    C.data.free()\n",
    "    print(\"Time spent in matmul_evaluatror, ms:\", (eval_end - eval_begin) // 1000000)\n",
    "    print(\"Best candidate idx:\", best_idx)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn matmul_autotune(C: Matrix, A: Matrix, B: Matrix):\n",
    "    alias best_impl: matmul_fn_sig_type\n",
    "    search[\n",
    "        matmul_fn_sig_type,\n",
    "        VariadicList(matmul_autotune_impl.__adaptive_set),\n",
    "        matmul_evaluator -> best_impl\n",
    "    ]()\n",
    "    # Run the best candidate\n",
    "    return best_impl(C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_evaluator, number of candidates:  6\n",
      "Optimizing for size: 512 x 512 x 512\n",
      "Time spent in matmul_evaluatror, ms: 4772\n",
      "Best candidate idx: 1\n",
      "10.334263067449122 GFLOP/s, a 4374.0417813367567 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[matmul_autotune](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn tile_parallel[\n",
    "    tiled_fn: Tile2DFunc, tile_x: Int, tile_y: Int\n",
    "](end_x: Int, end_y: Int):\n",
    "    # Note: this assumes that ends are multiples of the tiles\n",
    "    @parameter\n",
    "    fn row(yo: Int):\n",
    "        let y = tile_y * yo\n",
    "        for x in range(0, end_x, tile_x):\n",
    "            tiled_fn[tile_x, tile_y](x, y)\n",
    "\n",
    "    parallelize[row](end_y // tile_y, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import stack_allocation\n",
    "\n",
    "fn accumulate_registers(C: Matrix, A: Matrix, B: Matrix):\n",
    "    alias tile_k = 8\n",
    "    alias tile_k_unroll = 8\n",
    "    alias tile_i = 32\n",
    "    alias tile_j = nelts * 4\n",
    "\n",
    "    @parameter\n",
    "    fn calc_tile[tile_j: Int, tile_i: Int](jo: Int, io: Int):\n",
    "        # Allocate the tile of accumulators on the stack.\n",
    "        var accumulators = Matrix(\n",
    "            tile_i, tile_j, stack_allocation[tile_i * tile_j, DType.float32]()\n",
    "        )\n",
    "\n",
    "        for ko in range(0, A.cols, tile_k * tile_k_unroll):\n",
    "            for _ in range(tile_i):\n",
    "                for i in range(tile_k):\n",
    "                    @unroll\n",
    "                    for k in range(tile_k_unroll):\n",
    "                        @parameter\n",
    "                        fn calc_tile_cols[nelts: Int](j: Int):\n",
    "                            accumulators.store[nelts](\n",
    "                                i,\n",
    "                                j,\n",
    "                                accumulators.load[nelts](i, j)\n",
    "                                + A[io + i, ko + k]\n",
    "                                * B.load[nelts](ko + k, jo + j)\n",
    "                            ) \n",
    "\n",
    "                        vectorize_unroll[\n",
    "                            nelts, tile_j // nelts, calc_tile_cols\n",
    "                        ](tile_j)\n",
    "\n",
    "        # Copy the local tile to the output\n",
    "        for i in range(tile_i):\n",
    "            for j in range(tile_j):\n",
    "                C[io + i, jo + j] = accumulators[i, j]\n",
    "\n",
    "    tile_parallel[calc_tile, tile_j, tile_i](C.cols, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.906935358355476 GFLOP/s, a 20276.911426154547 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "bench[accumulate_registers](p_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
